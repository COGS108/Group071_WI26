{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    " Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is 0\n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|                                  | **Unsatisfactory**                                                                                                                                                                                                                                                                                                                        | **Developing**                                                                                                                                                                                                       | **Proficient**                                                                                                                                                                                            | **Excellent**                                                                                                                                                                            |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **EDA relevance**                | EDA is mostly neither relevant to the question nor helpful in figuring out how to address the question. Or the EDA does address the question, but many obviously relevant variables / analyses / figures were not included. | EDA is partly irrelevant/unhelpful. EDA missed one or two obvioulsy relevant analysis (distributions of single variables or relationships between variables) | EDA includes the obviously relevant / helpful variables in addressing the question.                                                              | Thorough EDA fully explored the dataset                                                                                                                 |\n",
    "| **EDA analysis and description** | Many of the analyses are poor choices (e.g., using means instead of medians for obviously skewed data), or are poorly described in the text, or do not aid understanding the data                                                                                                                                                     | Some of the analyses are poor choices, or are poorly described in the text, or do not aid understanding the data                                                                                                 | All analyses are correct choices. Only one or two have minor issues in the text descriptions supporting them. Mostly they fit well with other elements of the EDA and support understanding the data  | All analyses are correct choices with clear text descriptions supporting them. The figures fit well with the other elements of the EDA, producing a clear understanding of the data. |\n",
    "| **EDA figures**                  | Many of the figures are poor plot choices (e.g., using a bar plot to represent a time series where it would be better to use a line plot) or have poor aesthetics (including colormap, data point shape/color, axis labels, titles, annotations, text legibility) or do not aid understanding the data                                | Some of the figures are poor plot choices or have poor aesthetics. Some figures do not aid understanding the data                                                                                                | All figures are correct plot choices. Only one or two have minor questionable aesthetic choices. The figures mostly fit well with the other elements of the EDA and support understanding the data    | All figures are correct plot choices with beautiful aesthetics. The figures fit well with the other elements of the EDA, producing a clear understanding of the data.                |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Aditya Jadhav: Conceptualization, Data curation, Analysis, Writing – review & editing\n",
    "- Swayam Dani: Conceptualization, Methodology, Analysis, Visualization\n",
    "- Albert Bunyi: Data curation, Software, Analysis\n",
    "- Sean Yang: Background research, Visualization, Writing – original draft\n",
    "- Benjamin Balingit: Project administration, Methodology, Writing – original draft, Writing – review & editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does tyre degradation within individual stints, measured as the difference between the fastest lap and the final lap of that stint, differ between Red Bull Racing drivers across circuits during the 2023 to 2025 regulation era, and how is that degradation related to the tyre age at the end of the stint?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula 1 is a technologically advanced motorsport in which race performance is shaped not only by final results, but also by underlying factors such as tyre behavior, car setup, and track characteristics. Modern Formula 1 cars operate at the intersection of mechanical engineering, aerodynamics, and data-driven decision making. Over recent decades, advancements in engineering and data collection have made it possible to analyze race performance at a much finer granularity, including lap-by-lap pace and stint-level trends. Prior work has shown that these factors play a critical role in shaping race dynamics, particularly through tyre degradation and consistency of lap times over a race distance.\n",
    "\n",
    "Engineering-focused analyses of Formula 1 emphasize how regulatory stability and technical innovation influence performance trends over time. For example, a historical review of Formula 1 engineering development highlights how improvements in materials, aerodynamics, and power units have steadily increased both performance and data availability in the sport (Evolution of Formula One Motorsport, Academia.edu). This work demonstrates that as engineering systems become more sophisticated, performance differences increasingly emerge through operational factors such as tyre management and race strategy rather than raw speed alone. This context motivates a closer examination of lap-level performance metrics, which can reveal meaningful patterns beyond race outcomes.\n",
    "\n",
    "More focused prior work has examined tyre compounds and degradation directly. The official Formula 1 tyre guide explains how different compounds are designed to trade off grip and durability, with softer tyres providing higher initial performance at the cost of faster degradation (Formula1.com, Beginner's Guide to F1 Tyres). Complementing this practical perspective, recent academic research has modeled tyre degradation using lap-time data, demonstrating that degradation can be quantified as a systematic increase in lap times over a stint rather than random noise (arXiv:2512.00640). These studies show that tyre degradation and lap-time variability are measurable, interpretable phenomena. However, much of this work focuses on individual races or modeling approaches, rather than descriptive, multi-season analysis. Our project builds on these insights by examining lap-time degradation and driver consistency across multiple seasons (2021-2025), tyre compounds, and track types using publicly available race data.\n",
    "\n",
    "https://www.academia.edu/129272726/EVOLUTION_OF_FORMULA_ONE_F1_MOTORSPORTS_AND_ITS_TOP_NOTCH_ADVANCEMENT_IN_ENGINEERING_INNOVATIONS_ACROSS_THE_RACING_INDUSTRY\n",
    "\n",
    "https://www.formula1.com/en/latest/article/the-beginners-guide-to-formula-1-tyres.61SvF0Kfg29UR2SPhakDqd?utm_source\n",
    "\n",
    "https://arxiv.org/abs/2512.00640?utm_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that softer tyre compounds will show faster lap-time degradation than harder compounds across all tracks. We also expect that in lap-times will be shorter earlier in the stint when the tyres are fresher as compared to later in the stint when the tyres are older. We anticipate that the tyre degradation for both drivers of the Red Bull Racing team will be similar due to running the same car. Finally, we anticipate that driver consistency will vary by track type but remain relatively stable within the same driver across races."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: REPLACE the contents of this cell and the one below with your work, including any updates to recover points lost in your data checkpoint feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://api.openf1.org/v1/drivers?&csv=true', 'filename':'drivers.csv'},\n",
    "    { 'url': 'https://api.openf1.org/v1/stints?&csv=true', 'filename':'stints.csv'},\n",
    "    { 'url': 'https://api.openf1.org/v1/sessions?&csv=true', 'filename':'sessions.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenF1 RedBull drivers' stint tyre degredations & laptimes\n",
    "\n",
    "\n",
    "Description: OpenF1 is a data set that includes 18 endpoints, often ranging from team radio to throttle traces. It includes data such as but not limited to, car telemetry, lap times, race positions, pit stops, team radio, weather, race control and championship standings. Data will be accessed via CSV format to API calls. As live data requires a paid account, we will not be considering live data from this set. The endpoints that we decided to use for our purposes are: sessions, drivers, and stints. The important variables that we will be using for our dataset is: compound, driver_number, lap_end, lap_start, meeting_key, session_key, stint_number, tyre_age_at_start, lap_end_duration, fastest_lap_duration.\n",
    "\n",
    "The units for tyre_age_at_start is an integer in number of laps old. The units for lap_end_duration is seconds. The units for fastest_lap_duration is seconds. We are comparing the fastest lap time rather than the first lap of the stint as tyres need to warm up before they get to a working temperature where they are optimal and the lap times become a minimum. This could take a number of laps into the stint so we did not choose to take the first lap of the stint as the best possible lap time to compare for degredation. We chose to look at the lap time of the last lap of the stint as this would be the stint where the tyres are most worn and thus would lead to the greatest point of comparison.\n",
    "\n",
    "We tried to limit the variability of the dataset by limiting our dataset to one constructor team, RedBull racing, to ensure that there are no differences in the cars that would lead to differences in tyre degredation. One concern is that the dataset does not take into account the unique characteristics of each circuit which could lead to longer tyre lifetime or shorter lifetimes. Additionally, F1 is a very dynamic sport and there are many events occuring at the same time that lead to strategy changes during the race that could lead to the drivers opting to extend the stint to perform an \"overcut\" on their opponents, or pitting early to perform an \"undercut\" on their opponents. This is a variable that we simply cannot predict or take into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Drivers shape: (7310, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>broadcast_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>driver_number</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>headshot_url</th>\n",
       "      <th>last_name</th>\n",
       "      <th>meeting_key</th>\n",
       "      <th>name_acronym</th>\n",
       "      <th>session_key</th>\n",
       "      <th>team_colour</th>\n",
       "      <th>team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M VERSTAPPEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>Max VERSTAPPEN</td>\n",
       "      <td>https://www.formula1.com/content/dam/fom-websi...</td>\n",
       "      <td>Verstappen</td>\n",
       "      <td>1140</td>\n",
       "      <td>VER</td>\n",
       "      <td>7763</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L SARGEANT</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Logan SARGEANT</td>\n",
       "      <td>https://www.formula1.com/content/dam/fom-websi...</td>\n",
       "      <td>Sargeant</td>\n",
       "      <td>1140</td>\n",
       "      <td>SAR</td>\n",
       "      <td>7763</td>\n",
       "      <td>37BEDD</td>\n",
       "      <td>Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L NORRIS</td>\n",
       "      <td>GBR</td>\n",
       "      <td>4</td>\n",
       "      <td>Lando</td>\n",
       "      <td>Lando NORRIS</td>\n",
       "      <td>https://www.formula1.com/content/dam/fom-websi...</td>\n",
       "      <td>Norris</td>\n",
       "      <td>1140</td>\n",
       "      <td>NOR</td>\n",
       "      <td>7763</td>\n",
       "      <td>F58020</td>\n",
       "      <td>McLaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P GASLY</td>\n",
       "      <td>FRA</td>\n",
       "      <td>10</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>Pierre GASLY</td>\n",
       "      <td>https://www.formula1.com/content/dam/fom-websi...</td>\n",
       "      <td>Gasly</td>\n",
       "      <td>1140</td>\n",
       "      <td>GAS</td>\n",
       "      <td>7763</td>\n",
       "      <td>2293D1</td>\n",
       "      <td>Alpine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S PEREZ</td>\n",
       "      <td>MEX</td>\n",
       "      <td>11</td>\n",
       "      <td>Sergio</td>\n",
       "      <td>Sergio PEREZ</td>\n",
       "      <td>https://www.formula1.com/content/dam/fom-websi...</td>\n",
       "      <td>Perez</td>\n",
       "      <td>1140</td>\n",
       "      <td>PER</td>\n",
       "      <td>7763</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  broadcast_name country_code  driver_number first_name       full_name  \\\n",
       "0   M VERSTAPPEN          NED              1        Max  Max VERSTAPPEN   \n",
       "1     L SARGEANT          USA              2      Logan  Logan SARGEANT   \n",
       "2       L NORRIS          GBR              4      Lando    Lando NORRIS   \n",
       "3        P GASLY          FRA             10     Pierre    Pierre GASLY   \n",
       "4        S PEREZ          MEX             11     Sergio    Sergio PEREZ   \n",
       "\n",
       "                                        headshot_url   last_name  meeting_key  \\\n",
       "0  https://www.formula1.com/content/dam/fom-websi...  Verstappen         1140   \n",
       "1  https://www.formula1.com/content/dam/fom-websi...    Sargeant         1140   \n",
       "2  https://www.formula1.com/content/dam/fom-websi...      Norris         1140   \n",
       "3  https://www.formula1.com/content/dam/fom-websi...       Gasly         1140   \n",
       "4  https://www.formula1.com/content/dam/fom-websi...       Perez         1140   \n",
       "\n",
       "  name_acronym  session_key team_colour        team_name  \n",
       "0          VER         7763      3671C6  Red Bull Racing  \n",
       "1          SAR         7763      37BEDD         Williams  \n",
       "2          NOR         7763      F58020          McLaren  \n",
       "3          GAS         7763      2293D1           Alpine  \n",
       "4          PER         7763      3671C6  Red Bull Racing  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "broadcast_name       0\n",
       "country_code      2602\n",
       "driver_number        0\n",
       "first_name          15\n",
       "full_name            0\n",
       "headshot_url       335\n",
       "last_name           15\n",
       "meeting_key          0\n",
       "name_acronym         0\n",
       "session_key          0\n",
       "team_colour         15\n",
       "team_name           15\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "broadcast_name    object\n",
       "country_code      object\n",
       "driver_number      int64\n",
       "first_name        object\n",
       "full_name         object\n",
       "headshot_url      object\n",
       "last_name         object\n",
       "meeting_key        int64\n",
       "name_acronym      object\n",
       "session_key        int64\n",
       "team_colour       object\n",
       "team_name         object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows before filtering: 7310\n",
      "Rows after filtering: 726\n",
      "Rows removed: 6584\n",
      "\n",
      "Columns after dropping headshot_url:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['broadcast_name', 'country_code', 'driver_number', 'first_name',\n",
       "       'full_name', 'last_name', 'meeting_key', 'name_acronym', 'session_key',\n",
       "       'team_colour', 'team_name'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of cleaned Red Bull drivers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>broadcast_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>driver_number</th>\n",
       "      <th>first_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>meeting_key</th>\n",
       "      <th>name_acronym</th>\n",
       "      <th>session_key</th>\n",
       "      <th>team_colour</th>\n",
       "      <th>team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M VERSTAPPEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>Max VERSTAPPEN</td>\n",
       "      <td>Verstappen</td>\n",
       "      <td>1140</td>\n",
       "      <td>VER</td>\n",
       "      <td>7763</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S PEREZ</td>\n",
       "      <td>MEX</td>\n",
       "      <td>11</td>\n",
       "      <td>Sergio</td>\n",
       "      <td>Sergio PEREZ</td>\n",
       "      <td>Perez</td>\n",
       "      <td>1140</td>\n",
       "      <td>PER</td>\n",
       "      <td>7763</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S PEREZ</td>\n",
       "      <td>MEX</td>\n",
       "      <td>11</td>\n",
       "      <td>Sergio</td>\n",
       "      <td>Sergio PEREZ</td>\n",
       "      <td>Perez</td>\n",
       "      <td>1140</td>\n",
       "      <td>PER</td>\n",
       "      <td>7764</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M VERSTAPPEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>Max VERSTAPPEN</td>\n",
       "      <td>Verstappen</td>\n",
       "      <td>1140</td>\n",
       "      <td>VER</td>\n",
       "      <td>9222</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M VERSTAPPEN</td>\n",
       "      <td>NED</td>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>Max VERSTAPPEN</td>\n",
       "      <td>Verstappen</td>\n",
       "      <td>1141</td>\n",
       "      <td>VER</td>\n",
       "      <td>7765</td>\n",
       "      <td>3671C6</td>\n",
       "      <td>Red Bull Racing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  broadcast_name country_code  driver_number first_name       full_name  \\\n",
       "0   M VERSTAPPEN          NED              1        Max  Max VERSTAPPEN   \n",
       "1        S PEREZ          MEX             11     Sergio    Sergio PEREZ   \n",
       "2        S PEREZ          MEX             11     Sergio    Sergio PEREZ   \n",
       "3   M VERSTAPPEN          NED              1        Max  Max VERSTAPPEN   \n",
       "4   M VERSTAPPEN          NED              1        Max  Max VERSTAPPEN   \n",
       "\n",
       "    last_name  meeting_key name_acronym  session_key team_colour  \\\n",
       "0  Verstappen         1140          VER         7763      3671C6   \n",
       "1       Perez         1140          PER         7763      3671C6   \n",
       "2       Perez         1140          PER         7764      3671C6   \n",
       "3  Verstappen         1140          VER         9222      3671C6   \n",
       "4  Verstappen         1141          VER         7765      3671C6   \n",
       "\n",
       "         team_name  \n",
       "0  Red Bull Racing  \n",
       "1  Red Bull Racing  \n",
       "2  Red Bull Racing  \n",
       "3  Red Bull Racing  \n",
       "4  Red Bull Racing  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Drivers cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "drivers = pd.read_csv(\"./data/00-raw/drivers.csv\")\n",
    "\n",
    "# ===============================\n",
    "# Inspect Raw Drivers Data\n",
    "# ===============================\n",
    "print(\"Raw Drivers shape:\", drivers.shape)\n",
    "display(drivers.head())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(drivers.isna().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(drivers.dtypes)\n",
    "\n",
    "# ===============================\n",
    "# Filter Red Bull Drivers\n",
    "# ===============================\n",
    "before_rows = len(drivers)\n",
    "\n",
    "redbull_drivers = (\n",
    "    drivers[drivers[\"team_name\"].str.contains(\"Red Bull\", case=False, na=False)]\n",
    "    .drop(columns=[\"headshot_url\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "after_rows = len(redbull_drivers)\n",
    "\n",
    "print(\"\\nRows before filtering:\", before_rows)\n",
    "print(\"Rows after filtering:\", after_rows)\n",
    "print(\"Rows removed:\", before_rows - after_rows)\n",
    "\n",
    "print(\"\\nColumns after dropping headshot_url:\")\n",
    "display(redbull_drivers.columns)\n",
    "\n",
    "print(\"\\nPreview of cleaned Red Bull drivers:\")\n",
    "display(redbull_drivers.head())\n",
    "\n",
    "redbull_drivers.to_csv(\"./data/01-interim/redbull_drivers.csv\", index=False)\n",
    "\n",
    "print(\"\\nDrivers cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw stints shape: (30242, 8)\n",
      "Red Bull drivers shape: (726, 11)\n",
      "\n",
      "Rows before filtering: 30242\n",
      "Rows after filtering: 5742\n",
      "Rows removed: 24500\n",
      "\n",
      "Checking required columns exist:\n",
      "compound: True\n",
      "driver_number: True\n",
      "lap_end: True\n",
      "lap_start: True\n",
      "meeting_key: True\n",
      "session_key: True\n",
      "stint_number: True\n",
      "tyre_age_at_start: True\n",
      "lap_end_duration: False\n",
      "fastest_lap_duration: False\n",
      "\n",
      "Preview of Red Bull stints:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>driver_number</th>\n",
       "      <th>lap_end</th>\n",
       "      <th>lap_start</th>\n",
       "      <th>meeting_key</th>\n",
       "      <th>session_key</th>\n",
       "      <th>stint_number</th>\n",
       "      <th>tyre_age_at_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_UNKNOWN</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_UNKNOWN</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       compound  driver_number  lap_end  lap_start  meeting_key  session_key  \\\n",
       "0        MEDIUM             22      4.0        1.0         1140         7763   \n",
       "1  TEST_UNKNOWN             11      4.0        1.0         1140         7763   \n",
       "2        MEDIUM             22      7.0        4.0         1140         7763   \n",
       "3        MEDIUM             22     10.0        7.0         1140         7763   \n",
       "4  TEST_UNKNOWN             11      7.0        4.0         1140         7763   \n",
       "\n",
       "   stint_number  tyre_age_at_start  \n",
       "0             1               12.0  \n",
       "1             1                0.0  \n",
       "2             2               15.0  \n",
       "3             3               18.0  \n",
       "4             2                3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Red Bull stint filtering complete.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Load Red Bull Drivers + Raw Stints\n",
    "# ===============================\n",
    "redbull_drivers = pd.read_csv(\"./data/01-interim/redbull_drivers.csv\")\n",
    "stints = pd.read_csv(\"./data/00-raw/stints.csv\")\n",
    "\n",
    "print(\"Raw stints shape:\", stints.shape)\n",
    "print(\"Red Bull drivers shape:\", redbull_drivers.shape)\n",
    "\n",
    "# ===============================\n",
    "# Filter Stints to Red Bull Only\n",
    "# ===============================\n",
    "rb_numbers = redbull_drivers[\"driver_number\"].unique()\n",
    "\n",
    "before_rows = len(stints)\n",
    "\n",
    "rb_stints = stints[\n",
    "    stints[\"driver_number\"].isin(rb_numbers)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "after_rows = len(rb_stints)\n",
    "\n",
    "print(\"\\nRows before filtering:\", before_rows)\n",
    "print(\"Rows after filtering:\", after_rows)\n",
    "print(\"Rows removed:\", before_rows - after_rows)\n",
    "\n",
    "# ===============================\n",
    "# Verify Important Columns Exist\n",
    "# ===============================\n",
    "important_columns = [\n",
    "    \"compound\",\n",
    "    \"driver_number\",\n",
    "    \"lap_end\",\n",
    "    \"lap_start\",\n",
    "    \"meeting_key\",\n",
    "    \"session_key\",\n",
    "    \"stint_number\",\n",
    "    \"tyre_age_at_start\",\n",
    "    \"lap_end_duration\",\n",
    "    \"fastest_lap_duration\"\n",
    "]\n",
    "\n",
    "print(\"\\nChecking required columns exist:\")\n",
    "for col in important_columns:\n",
    "    print(f\"{col}:\", col in rb_stints.columns)\n",
    "\n",
    "# ===============================\n",
    "# Preview Filtered Data\n",
    "# ===============================\n",
    "print(\"\\nPreview of Red Bull stints:\")\n",
    "display(rb_stints.head())\n",
    "\n",
    "rb_stints.to_csv(\"./data/01-interim/rb_stints.csv\", index=False)\n",
    "\n",
    "print(\"\\nRed Bull stint filtering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Sessions shape: (490, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circuit_key</th>\n",
       "      <th>circuit_short_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_key</th>\n",
       "      <th>country_name</th>\n",
       "      <th>date_end</th>\n",
       "      <th>date_start</th>\n",
       "      <th>gmt_offset</th>\n",
       "      <th>location</th>\n",
       "      <th>meeting_key</th>\n",
       "      <th>session_key</th>\n",
       "      <th>session_name</th>\n",
       "      <th>session_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>BRN</td>\n",
       "      <td>36</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>2023-02-23 16:30:00+00:00</td>\n",
       "      <td>2023-02-23 07:00:00+00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>1140</td>\n",
       "      <td>9222</td>\n",
       "      <td>Day 1</td>\n",
       "      <td>Practice</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>BRN</td>\n",
       "      <td>36</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>2023-02-24 16:30:00+00:00</td>\n",
       "      <td>2023-02-24 07:00:00+00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>1140</td>\n",
       "      <td>7763</td>\n",
       "      <td>Day 2</td>\n",
       "      <td>Practice</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>BRN</td>\n",
       "      <td>36</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>2023-02-25 16:30:00+00:00</td>\n",
       "      <td>2023-02-25 07:00:00+00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>1140</td>\n",
       "      <td>7764</td>\n",
       "      <td>Day 3</td>\n",
       "      <td>Practice</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>BRN</td>\n",
       "      <td>36</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>2023-03-03 12:30:00+00:00</td>\n",
       "      <td>2023-03-03 11:30:00+00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>1141</td>\n",
       "      <td>7765</td>\n",
       "      <td>Practice 1</td>\n",
       "      <td>Practice</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>BRN</td>\n",
       "      <td>36</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>2023-03-03 16:00:00+00:00</td>\n",
       "      <td>2023-03-03 15:00:00+00:00</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Sakhir</td>\n",
       "      <td>1141</td>\n",
       "      <td>7766</td>\n",
       "      <td>Practice 2</td>\n",
       "      <td>Practice</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   circuit_key circuit_short_name country_code  country_key country_name  \\\n",
       "0           63             Sakhir          BRN           36      Bahrain   \n",
       "1           63             Sakhir          BRN           36      Bahrain   \n",
       "2           63             Sakhir          BRN           36      Bahrain   \n",
       "3           63             Sakhir          BRN           36      Bahrain   \n",
       "4           63             Sakhir          BRN           36      Bahrain   \n",
       "\n",
       "                    date_end                 date_start gmt_offset location  \\\n",
       "0  2023-02-23 16:30:00+00:00  2023-02-23 07:00:00+00:00   03:00:00   Sakhir   \n",
       "1  2023-02-24 16:30:00+00:00  2023-02-24 07:00:00+00:00   03:00:00   Sakhir   \n",
       "2  2023-02-25 16:30:00+00:00  2023-02-25 07:00:00+00:00   03:00:00   Sakhir   \n",
       "3  2023-03-03 12:30:00+00:00  2023-03-03 11:30:00+00:00   03:00:00   Sakhir   \n",
       "4  2023-03-03 16:00:00+00:00  2023-03-03 15:00:00+00:00   03:00:00   Sakhir   \n",
       "\n",
       "   meeting_key  session_key session_name session_type  year  \n",
       "0         1140         9222        Day 1     Practice  2023  \n",
       "1         1140         7763        Day 2     Practice  2023  \n",
       "2         1140         7764        Day 3     Practice  2023  \n",
       "3         1141         7765   Practice 1     Practice  2023  \n",
       "4         1141         7766   Practice 2     Practice  2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "circuit_key           0\n",
       "circuit_short_name    0\n",
       "country_code          0\n",
       "country_key           0\n",
       "country_name          0\n",
       "date_end              0\n",
       "date_start            0\n",
       "gmt_offset            0\n",
       "location              0\n",
       "meeting_key           0\n",
       "session_key           0\n",
       "session_name          0\n",
       "session_type          0\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "circuit_key            int64\n",
       "circuit_short_name    object\n",
       "country_code          object\n",
       "country_key            int64\n",
       "country_name          object\n",
       "date_end              object\n",
       "date_start            object\n",
       "gmt_offset            object\n",
       "location              object\n",
       "meeting_key            int64\n",
       "session_key            int64\n",
       "session_name          object\n",
       "session_type          object\n",
       "year                   int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RB Stints before session merge: (5742, 8)\n",
      "\n",
      "After merge shape: (5742, 10)\n",
      "\n",
      "Preview after merge:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_key</th>\n",
       "      <th>year</th>\n",
       "      <th>session_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7763</td>\n",
       "      <td>2023</td>\n",
       "      <td>Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7763</td>\n",
       "      <td>2023</td>\n",
       "      <td>Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7763</td>\n",
       "      <td>2023</td>\n",
       "      <td>Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7763</td>\n",
       "      <td>2023</td>\n",
       "      <td>Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7763</td>\n",
       "      <td>2023</td>\n",
       "      <td>Practice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_key  year session_type\n",
       "0         7763  2023     Practice\n",
       "1         7763  2023     Practice\n",
       "2         7763  2023     Practice\n",
       "3         7763  2023     Practice\n",
       "4         7763  2023     Practice"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows before filtering: 5742\n",
      "Rows after filtering: 853\n",
      "Rows removed: 4889\n",
      "\n",
      "Remaining session types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "session_type\n",
       "Race    853\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining years:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "year\n",
       "2025    297\n",
       "2024    294\n",
       "2023    262\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final shape after dropping helper columns: (853, 8)\n",
      "\n",
      "Session filtering complete.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Load Sessions Data\n",
    "# ===============================\n",
    "sessions = pd.read_csv(\"./data/00-raw/sessions.csv\")\n",
    "\n",
    "print(\"Raw Sessions shape:\", sessions.shape)\n",
    "display(sessions.head())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(sessions.isna().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(sessions.dtypes)\n",
    "\n",
    "# ===============================\n",
    "# Load Red Bull Stints\n",
    "# ===============================\n",
    "rb_stints = pd.read_csv(\"./data/01-interim/rb_stints.csv\")\n",
    "\n",
    "print(\"\\nRB Stints before session merge:\", rb_stints.shape)\n",
    "\n",
    "# ===============================\n",
    "# Merge Session Metadata\n",
    "# ===============================\n",
    "rb_stints = rb_stints.merge(\n",
    "    sessions[[\"session_key\", \"year\", \"session_type\"]],\n",
    "    on=\"session_key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"\\nAfter merge shape:\", rb_stints.shape)\n",
    "\n",
    "print(\"\\nPreview after merge:\")\n",
    "display(rb_stints[[\"session_key\", \"year\", \"session_type\"]].head())\n",
    "\n",
    "# ===============================\n",
    "# Filter: Remove 2026 + Keep Only Race Sessions\n",
    "# ===============================\n",
    "before_filter = len(rb_stints)\n",
    "\n",
    "rb_stints = rb_stints[\n",
    "    (rb_stints[\"year\"].notna()) &\n",
    "    (rb_stints[\"year\"] != 2026) &\n",
    "    (rb_stints[\"session_type\"] == \"Race\")\n",
    "]\n",
    "\n",
    "after_filter = len(rb_stints)\n",
    "\n",
    "print(\"\\nRows before filtering:\", before_filter)\n",
    "print(\"Rows after filtering:\", after_filter)\n",
    "print(\"Rows removed:\", before_filter - after_filter)\n",
    "\n",
    "print(\"\\nRemaining session types:\")\n",
    "display(rb_stints[\"session_type\"].value_counts())\n",
    "\n",
    "print(\"\\nRemaining years:\")\n",
    "display(rb_stints[\"year\"].value_counts())\n",
    "\n",
    "# ===============================\n",
    "# Drop Helper Columns\n",
    "# ===============================\n",
    "rb_stints = rb_stints.drop(columns=[\"year\", \"session_type\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFinal shape after dropping helper columns:\", rb_stints.shape)\n",
    "\n",
    "rb_stints.to_csv(\"./data/01-interim/rb_stints.csv\", index=False)\n",
    "\n",
    "print(\"\\nSession filtering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before date filtering: (853, 9)\n",
      "Rows matching bad dates: 91\n",
      "Dataset shape after date filtering: (762, 8)\n",
      "Rows removed: 91\n",
      "\n",
      "Any bad dates remaining?: False\n",
      "\n",
      "Date cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Remove Known Corrupted / Invalid Dates\n",
    "# ===============================\n",
    "\n",
    "bad_dates = pd.to_datetime([\n",
    "    \"2023-04-29\",\n",
    "    \"2023-07-29\",\n",
    "    \"2023-10-07\",\n",
    "    \"2023-10-21\",\n",
    "    \"2023-11-04\",\n",
    "    \"2024-04-20\",\n",
    "    \"2024-05-04\",\n",
    "    \"2024-06-29\",\n",
    "    \"2024-10-19\",\n",
    "    \"2024-11-02\",\n",
    "    \"2024-11-30\",\n",
    "    \"2025-03-22\",\n",
    "    \"2025-05-03\",\n",
    "    \"2025-07-26\",\n",
    "    \"2025-10-18\",\n",
    "    \"2025-11-08\",\n",
    "    \"2025-11-29\",\n",
    "]).date\n",
    "\n",
    "# Merge date_start into stints\n",
    "tmp = rb_stints.merge(\n",
    "    sessions[[\"session_key\", \"date_start\"]],\n",
    "    on=\"session_key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "tmp[\"date_start\"] = pd.to_datetime(\n",
    "    tmp[\"date_start\"], errors=\"coerce\"\n",
    ").dt.date\n",
    "\n",
    "print(\"Dataset shape before date filtering:\", tmp.shape)\n",
    "\n",
    "# Count how many rows match bad dates\n",
    "bad_rows = tmp[\"date_start\"].isin(bad_dates).sum()\n",
    "print(\"Rows matching bad dates:\", bad_rows)\n",
    "\n",
    "# Apply filter\n",
    "filtered = tmp[\n",
    "    ~tmp[\"date_start\"].isin(bad_dates)\n",
    "].drop(columns=[\"date_start\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shape after date filtering:\", filtered.shape)\n",
    "print(\"Rows removed:\", tmp.shape[0] - filtered.shape[0])\n",
    "\n",
    "# Verify no bad dates remain\n",
    "check = filtered.merge(\n",
    "    sessions[[\"session_key\", \"date_start\"]],\n",
    "    on=\"session_key\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "check[\"date_start\"] = pd.to_datetime(check[\"date_start\"]).dt.date\n",
    "\n",
    "print(\"\\nAny bad dates remaining?:\",\n",
    "      check[\"date_start\"].isin(bad_dates).any())\n",
    "\n",
    "filtered.to_csv(\"./data/01-interim/rb_stints.csv\", index=False)\n",
    "\n",
    "print(\"\\nDate cleaning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (762, 8)\n",
      "\n",
      "Missing lap_start: 9\n",
      "Missing lap_end: 9\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m session_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(session_key)\n\u001b[1;32m     27\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openf1.org/v1/laps?driver_number=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdriver_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&session_key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m laps \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m laps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m laps\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/json/_json.py:944\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    937\u001b[0m filepath_or_buffer \u001b[38;5;241m=\u001b[39m stringify_path(filepath_or_buffer)\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_url(filepath_or_buffer)\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_fsspec_url(filepath_or_buffer)\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    943\u001b[0m ):\n\u001b[0;32m--> 944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    959\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Compute Fastest Lap + End Lap Duration per Stint\n",
    "# ===============================\n",
    "\n",
    "rb_stints = pd.read_csv(\"./data/01-interim/rb_stints.csv\")\n",
    "\n",
    "print(\"Initial dataset shape:\", rb_stints.shape)\n",
    "\n",
    "# Convert lap columns to numeric\n",
    "rb_stints[\"lap_start\"] = pd.to_numeric(rb_stints[\"lap_start\"], errors=\"coerce\")\n",
    "rb_stints[\"lap_end\"]   = pd.to_numeric(rb_stints[\"lap_end\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nMissing lap_start:\", rb_stints[\"lap_start\"].isna().sum())\n",
    "print(\"Missing lap_end:\", rb_stints[\"lap_end\"].isna().sum())\n",
    "\n",
    "# Initialize new columns\n",
    "rb_stints[\"lap_end_duration\"] = np.nan\n",
    "rb_stints[\"fastest_lap_duration\"] = np.nan\n",
    "\n",
    "groups = rb_stints.groupby([\"driver_number\", \"session_key\"]).groups\n",
    "\n",
    "for (driver_number, session_key), idx in groups.items():\n",
    "\n",
    "    driver_number = int(driver_number)\n",
    "    session_key = int(session_key)\n",
    "\n",
    "    url = f\"https://api.openf1.org/v1/laps?driver_number={driver_number}&session_key={session_key}\"\n",
    "    laps = pd.read_json(url)\n",
    "\n",
    "    if laps is None or laps.empty:\n",
    "        continue\n",
    "\n",
    "    laps[\"lap_number\"] = pd.to_numeric(laps[\"lap_number\"], errors=\"coerce\")\n",
    "    laps[\"lap_duration\"] = pd.to_numeric(laps[\"lap_duration\"], errors=\"coerce\")\n",
    "\n",
    "    for i in idx:\n",
    "        lap_start = rb_stints.at[i, \"lap_start\"]\n",
    "        lap_end = rb_stints.at[i, \"lap_end\"]\n",
    "\n",
    "        if pd.isna(lap_start) or pd.isna(lap_end):\n",
    "            continue\n",
    "\n",
    "        lap_start = int(lap_start)\n",
    "        lap_end = int(lap_end)\n",
    "\n",
    "        stint_laps = laps[\n",
    "            (laps[\"lap_number\"] >= lap_start) &\n",
    "            (laps[\"lap_number\"] <= lap_end)\n",
    "        ]\n",
    "\n",
    "        if stint_laps.empty:\n",
    "            continue\n",
    "\n",
    "        rb_stints.at[i, \"fastest_lap_duration\"] = stint_laps[\"lap_duration\"].min(skipna=True)\n",
    "\n",
    "        end_row = stint_laps[stint_laps[\"lap_number\"] == lap_end]\n",
    "        if not end_row.empty:\n",
    "            rb_stints.at[i, \"lap_end_duration\"] = end_row[\"lap_duration\"].iloc[0]\n",
    "\n",
    "# ===============================\n",
    "# Show Results\n",
    "# ===============================\n",
    "\n",
    "print(\"\\nPreview of computed columns:\")\n",
    "display(rb_stints[[\n",
    "    \"driver_number\",\n",
    "    \"session_key\",\n",
    "    \"lap_start\",\n",
    "    \"lap_end\",\n",
    "    \"fastest_lap_duration\",\n",
    "    \"lap_end_duration\"\n",
    "]].head())\n",
    "\n",
    "print(\"\\nMissing values in computed columns:\")\n",
    "display(rb_stints[[\n",
    "    \"fastest_lap_duration\",\n",
    "    \"lap_end_duration\"\n",
    "]].isna().sum())\n",
    "\n",
    "rb_stints.to_csv(\"./data/02-processed/rb_stints.csv\", index=False)\n",
    "\n",
    "print(\"\\nLap duration computation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Cleaning Step: Remove Incomplete Stints\n",
    "\n",
    "We remove any stints that are missing any critical values for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before dropna: (762, 10)\n",
      "Dataset shape after dropna: (106, 10)\n",
      "Rows removed: 656\n",
      "Percent removed: 86.09 %\n",
      "\n",
      "Final dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>driver_number</th>\n",
       "      <th>lap_end</th>\n",
       "      <th>lap_start</th>\n",
       "      <th>meeting_key</th>\n",
       "      <th>session_key</th>\n",
       "      <th>stint_number</th>\n",
       "      <th>tyre_age_at_start</th>\n",
       "      <th>lap_end_duration</th>\n",
       "      <th>fastest_lap_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOFT</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1141</td>\n",
       "      <td>7953</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101.295</td>\n",
       "      <td>97.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOFT</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1141</td>\n",
       "      <td>7953</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.964</td>\n",
       "      <td>97.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARD</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1141</td>\n",
       "      <td>7953</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.373</td>\n",
       "      <td>96.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1142</td>\n",
       "      <td>7779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.348</td>\n",
       "      <td>93.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARD</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1142</td>\n",
       "      <td>7779</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.906</td>\n",
       "      <td>91.906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  compound  driver_number  lap_end  lap_start  meeting_key  session_key  \\\n",
       "0     SOFT              1     14.0        1.0         1141         7953   \n",
       "1     SOFT              1     36.0       15.0         1141         7953   \n",
       "2     HARD              1     57.0       37.0         1141         7953   \n",
       "3   MEDIUM              1     18.0        1.0         1142         7779   \n",
       "4     HARD              1     50.0       19.0         1142         7779   \n",
       "\n",
       "   stint_number  tyre_age_at_start  lap_end_duration  fastest_lap_duration  \n",
       "0             1                3.0           101.295                97.974  \n",
       "1             2                2.0           100.964                97.372  \n",
       "2             3                0.0            96.373                96.236  \n",
       "3             1                0.0           134.348                93.790  \n",
       "4             2                0.0            91.906                91.906  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cleaned dataset saved.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Final Cleaning: Remove Incomplete Stints\n",
    "# ===============================\n",
    "\n",
    "print(\"Dataset shape before dropna:\", rb_stints.shape)\n",
    "\n",
    "before_rows = len(rb_stints)\n",
    "\n",
    "rb_stints = rb_stints.dropna(\n",
    "    subset=[\n",
    "        \"lap_start\",\n",
    "        \"lap_end\",\n",
    "        \"lap_end_duration\",\n",
    "        \"fastest_lap_duration\"\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "after_rows = len(rb_stints)\n",
    "\n",
    "print(\"Dataset shape after dropna:\", rb_stints.shape)\n",
    "print(\"Rows removed:\", before_rows - after_rows)\n",
    "print(\"Percent removed:\", round((before_rows - after_rows) / before_rows * 100, 2), \"%\")\n",
    "\n",
    "print(\"\\nFinal dataset preview:\")\n",
    "display(rb_stints.head())\n",
    "\n",
    "rb_stints.to_csv(\"./data/02-processed/rb_stints.csv\", index=False)\n",
    "\n",
    "print(\"\\nFinal cleaned dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "Instructions: replace the words in this subsection with whatever words you need to setup and preview the EDA you're going to do.   \n",
    "\n",
    "Please explicitly load the fully wrangled data you will use from `data/02-processed`.  This is a good idea rather than forcing people to re-run the data getting / wrangling cells above.  Sometimes it takes a long time to get / wrangle data compared to reloading the fixed up dataset.\n",
    "\n",
    "Carry out whatever EDA you need to for your project in the code cells below.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context.\n",
    "\n",
    "Please note that you should consider the use of python modules in your work.  Any code which gets called repeatedly should be modularized. So if you run the same pre-processing, analysis or visualiazation on different subsets of the data, then you should turn that into a function or class.  Put that function or class in a .py file that lives in `modules/`.  Import the module you made and use it to get your work done.  For reference see `get_raw()` which is inside `modules/get_data.py`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 1 of EDA - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 of EDA if you need it  - please give it a better title than this\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "\n",
    "- put an X there if you've considered the item\n",
    "- IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "\n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section. You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\\\n",
    "<br>This project relies exclusively on publicly available Formula 1 race data, including lap times, tyre compounds, and circuit characteristics released by Formula 1, the FIA, and reputable third-party motorsport databases. No direct interaction with drivers, teams, or other individuals occurs, and no private or proprietary data are collected. Because the data are historical, observational, and already in the public domain, informed consent from individuals is not applicable in this context.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\\\n",
    "<br>We recognize that Formula 1 data collection may introduce biases related to race-specific events such as safety cars, red flags, weather changes, and retirements, which can disproportionately affect lap-time degradation measurements. Additionally, differences in track layouts and race lengths between street circuits and permanent circuits may lead to uneven representation across categories. To address these issues, we explicitly document data exclusions, normalize lap-time metrics where appropriate, and interpret results within the context of these known sources of bias rather than attributing outcomes solely to tyre compounds or driver performance.\n",
    "\n",
    "- **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "- **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    "<br>All our data comes from public databases<br>\n",
    "- **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "- **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "- **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "Data will only be stored for the duration of the course project. After the project is completed, local copies will be deleted and only final analysis outputs will remain in the project repository.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\\\n",
    "<br>Our analysis focuses on quantitative performance metrics and does not capture qualitative factors such as driver feedback, team communications, or real-time strategic decision-making during races. These perspectives may influence tyre management and lap-time consistency but are not directly observable in the available data. To mitigate this limitation, we contextualize findings using existing Formula 1 regulations, race reports, and established motorsport knowledge, and we avoid making causal claims that would require access to these missing perspectives.\n",
    "\n",
    " - [x] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\\\n",
    "<br>The dataset may reflect imbalances in tyre compound usage, circuit types, and competitive conditions across the 2021–2025 regulation era. For example, certain tyre compounds may be used more frequently at specific circuits, and stronger teams may complete longer stints under favorable conditions. We address these biases by stratifying analyses by circuit type, controlling for stint length, and clearly stating assumptions and limitations where confounding variables cannot be fully removed.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\\\n",
    "<br>All visualizations and summary statistics are designed to accurately reflect the underlying race data without exaggerating trends or masking variability. Axis scales, aggregation choices, and comparisons between tyre compounds and circuit types are selected to avoid misleading interpretations. Where variability is high or sample sizes differ across circuits or seasons, this uncertainty is clearly communicated rather than smoothed over.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\\\n",
    "<br>The analysis does not involve private or sensitive information. All data used consist of publicly available lap times, tyre choices, and circuit classifications that are widely reported in Formula 1 coverage. No attempts are made to infer personal characteristics or private behavior beyond what is explicitly observable in race performance data.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\\\n",
    "<br>The full analytical process, including data sources, preprocessing steps, filtering criteria, and modeling choices, is documented to ensure reproducibility. This documentation allows results to be independently verified and enables future review if errors, biases, or alternative interpretations are identified.\n",
    "\n",
    "### D. Modeling\n",
    "- **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "- **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\\\n",
    "<br>We carefully select modeling metrics to align with the research question and avoid misleading optimization. Instead of relying on a single outcome measure, we analyze multiple complementary metrics, including lap-time degradation rates and measures of lap-time variability to capture driver consistency. This approach reduces the risk that conclusions are driven by artifacts of a single metric and allows for a more nuanced comparison across tyre compounds and circuit types.\n",
    "\n",
    "- **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\\\n",
    "<br>We clearly communicate the limitations of our modeling approach, including the observational nature of Formula 1 race data, the presence of unobserved confounding variables such as weather and strategic decisions, and simplifications involved in classifying circuits and tyre behavior. Model outputs are presented as descriptive or associative findings rather than causal claims, and conclusions are framed to avoid overgeneralization beyond the scope of the data.\n",
    "\n",
    "### E. Deployment\n",
    "- **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "- **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "- **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\\\n",
    "<br>Although this project is not deployed as a production system, we acknowledge the possibility that analytical results could be misinterpreted or taken out of context. For example, findings about lap-time degradation or driver consistency could be incorrectly attributed solely to driver skill rather than broader factors such as team resources, race strategy, or external conditions. To mitigate this risk, results are presented with clear explanations, appropriate caveats, and explicit statements about the observational and non-causal nature of the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All team members will communicate regularly via Messages, GitHub issues, and biweekly zoom meetings to update one another on the current progress of their tasks.  \n",
    "- Expected tone: All team members will communicate with a friendly tone when bringing up issues, and will not personally target one another. For example: “ I am confused with X, could you explain further what you mean by that”  \n",
    "- Expectations around tasks: Tasks will just be assigned based on need, so there will not be any specialized roles.  \n",
    "- Expectations for struggling to deliver on time: Members will be expected to communicate if they are struggling to complete tasks on time, but if there are issues contacting anyone within the group, the group will try to take over the task within 2 days of the original deadline assigned.  \n",
    "- Each member will complete assigned tasks before agreed deadlines and notify the group early if delays arise.  \n",
    "- All analysis and writing will be reviewed by at least one other team member before submission.  \n",
    "- Disagreements will be resolved respectfully through discussion and reference to project goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Extraction & Stint Structuring  \n",
    "**Feb 6 – Feb 14**\n",
    "\n",
    "Since our unit of analysis is the stint, this phase focuses on building a clean stint-level dataset.\n",
    "\n",
    "### Tasks:\n",
    "- Filter dataset to Red Bull Racing drivers (2023–2025)  \n",
    "- Identify and separate individual stints  \n",
    "- For each stint, compute:\n",
    "  - Fastest lap  \n",
    "  - Final lap  \n",
    "  - Degradation gap (final lap time minus fastest lap time)  \n",
    "  - Tyre age on the final lap  \n",
    "- Validate data consistency and remove abnormal stints  \n",
    "\n",
    "### Deliverable:\n",
    "Clean, structured stint-level dataset ready for analysis  \n",
    "\n",
    "---\n",
    "\n",
    "## Phase 2: Exploratory Data Analysis (Checkpoint #2)  \n",
    "**Feb 15 – Feb 23**\n",
    "\n",
    "### Tasks:\n",
    "- Examine distributions of:\n",
    "  - Stint lengths  \n",
    "  - Tyre age at final lap  \n",
    "  - Degradation gaps  \n",
    "- Identify outliers and unusual patterns  \n",
    "- Generate initial visualizations:\n",
    "  - Fastest lap vs final lap scatter plot  \n",
    "  - Distribution of degradation gaps  \n",
    "  - Degradation vs tyre age  \n",
    "\n",
    "### Deliverable:\n",
    "EDA notebook with interpretations ready for submission  \n",
    "\n",
    "---\n",
    "\n",
    "## Phase 3: Intra-Team & Circuit-Level Analysis  \n",
    "**Feb 24 – Mar 3**\n",
    "\n",
    "### Tasks:\n",
    "- Compare degradation distributions between Red Bull drivers  \n",
    "- Analyze degradation across circuits  \n",
    "- Evaluate the relationship between tyre age and degradation  \n",
    "- Assess variation across seasons (2023, 2024, 2025)  \n",
    "- Finalize summary statistics and key comparisons  \n",
    "\n",
    "### Deliverable:\n",
    "Core analysis completed and metrics finalized  \n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Visualization & Writing  \n",
    "**Mar 4 – Mar 9**\n",
    "\n",
    "### Tasks:\n",
    "- Create polished final visualizations:\n",
    "  - Driver comparison plots  \n",
    "  - Degradation vs tyre age  \n",
    "  - Circuit-level variation  \n",
    "- Write:\n",
    "  - Background & Prior Work  \n",
    "  - Methods section (clearly stating stint as the unit of analysis)  \n",
    "  - Results interpretation  \n",
    "  - Ethics and bias discussion  \n",
    "  - Limitations  \n",
    "\n",
    "### Deliverable:\n",
    "Complete draft of final project notebook  \n",
    "\n",
    "---\n",
    "\n",
    "## Phase 5: Final Review & Submission  \n",
    "**Mar 10 – Mar 13**\n",
    "\n",
    "### Tasks:\n",
    "- Proofread and refine writing  \n",
    "- Ensure the research question is clearly answered  \n",
    "- Confirm all plots are labeled and interpreted  \n",
    "- Restart kernel and run the notebook end-to-end  \n",
    "- Final GitHub commit and submission  \n",
    "- Complete individual peer evaluations  \n",
    "\n",
    "**Deliverable:** Final Project Submission (March 13) (3/20 is the actual deadline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
